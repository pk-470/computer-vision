{"cells":[{"cell_type":"markdown","metadata":{"id":"f8zjZu2COpzC"},"source":["# Installations and imports\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BHmdjJ8PCcC"},"outputs":[],"source":["!pip install lightning wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zBbt222dOpJb"},"outputs":[],"source":["import os\n","import shutil\n","import csv\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import wandb\n","\n","import torch\n","from torch import optim\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","from pytorch_lightning.loggers import WandbLogger\n","\n","import torchmetrics\n","\n","from torchvision import transforms, models\n","\n","from torchsummary import summary\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import (\n","    precision_score,\n","    recall_score,\n","    f1_score,\n","    confusion_matrix,\n","    classification_report,\n",")"]},{"cell_type":"markdown","metadata":{"id":"1pYIwjr4TvGd"},"source":["Set random seed\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ej-Pr22RsUqo"},"outputs":[],"source":["RANDOM_SEED = 42\n","pl.seed_everything(RANDOM_SEED, workers=True)"]},{"cell_type":"markdown","metadata":{"id":"tOoB885j6GOp"},"source":["Login to wandb\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vd2uON3YeP1A"},"outputs":[],"source":["wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"1L-_V_qF_60V"},"source":["# Dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HmOcbisocNt0"},"outputs":[],"source":["# from google.colab import drive\n","\n","# drive.mount('/content/drive')\n","\n","# CHANGE PATH TO CURRENT DIRECTORY\n","DRIVE_DIR = \"/content/drive/MyDrive/Colab Notebooks/Computer Vision/Assignment 2/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQ0_I5xR1HLt"},"outputs":[],"source":["LABELS = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n","NUM_LABELS = len(LABELS)\n","\n","IM_H, IM_W = 48, 48"]},{"cell_type":"markdown","metadata":{"id":"civjXA2Cw8ui"},"source":["Load data and split into train/validation/test sets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4D1m5QW5nelJ"},"outputs":[],"source":["data_path = DRIVE_DIR + \"data/fer2013.csv\"\n","\n","# Training\n","train_images = []\n","train_labels = []\n","\n","# Validation\n","val_images = []\n","val_labels = []\n","\n","# Test\n","test_images = []\n","test_labels = []\n","\n","with open(data_path, \"r\") as file:\n","    csv_reader = csv.reader(file)\n","    next(csv_reader)  # Ignore header\n","\n","    for emotion, pixels, usage in csv_reader:\n","        pixels = [int(p) for p in pixels.split()]\n","        emotion = int(emotion)\n","\n","        if usage == \"Training\":\n","            train_images.append(pixels)\n","            train_labels.append(emotion)\n","\n","        elif usage == \"PrivateTest\":\n","            val_images.append(pixels)\n","            val_labels.append(emotion)\n","\n","        elif usage == \"PublicTest\":\n","            test_images.append(pixels)\n","            test_labels.append(emotion)\n","\n","train_images = np.array(train_images, dtype=np.uint8).reshape(\n","    (len(train_images), IM_H, IM_W, 1)\n",")\n","train_labels = np.array(train_labels, dtype=np.uint8)\n","\n","val_images = np.array(val_images, dtype=np.uint8).reshape(\n","    (len(val_images), IM_H, IM_W, 1)\n",")\n","val_labels = np.array(val_labels, dtype=np.uint8)\n","\n","test_images = np.array(test_images, dtype=np.uint8).reshape(\n","    (len(test_images), IM_H, IM_W, 1)\n",")\n","test_labels = np.array(test_labels, dtype=np.uint8)"]},{"cell_type":"markdown","metadata":{"id":"lWRsXuKM5ICj"},"source":["Dataset distribution\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bgbf_uYi5HJW"},"outputs":[],"source":["def dataset_distribution(labels, verbose=True):\n","    ratios = []\n","    labels_len = len(labels)\n","    if verbose:\n","        print(f\"Total images: {labels_len}\")\n","    for i, label in enumerate(LABELS):\n","        n = len(labels[labels == i])\n","        r = n / labels_len\n","        ratios.append(r)\n","\n","        if verbose:\n","            print(f\"- {label}: {n} ({r*100:0.2f}%)\")\n","\n","    return ratios"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-qCciUczApV"},"outputs":[],"source":["print(\"------ Train Dataset ------\")\n","_ = dataset_distribution(train_labels)\n","print()\n","print(\"------ Validation Dataset ------\")\n","_ = dataset_distribution(val_labels)\n","print()\n","print(\"------ Test Dataset ------\")\n","_ = dataset_distribution(test_labels)"]},{"cell_type":"markdown","metadata":{"id":"VbsHUKUGxyck"},"source":["Visualize the images\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNHopxx8xsjJ"},"outputs":[],"source":["def plot_image(image, label, save_as=None):\n","    plt.imshow(image, cmap=\"gray\")\n","    plt.axis(\"off\")\n","    plt.title(LABELS[label])\n","\n","    # Save\n","    if save_as:\n","        plt.savefig(save_as, bbox_inches=\"tight\")\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S6Xau9CIExd9"},"outputs":[],"source":["# Choose a test image from each label\n","ex_indices = np.zeros((NUM_LABELS,), dtype=np.uint8)\n","for i in range(NUM_LABELS):\n","    ex_indices[i] = np.where(test_labels == i)[0][0]\n","\n","# Collect images and labels\n","ex_images = test_images[ex_indices]\n","ex_labels = test_labels[ex_indices]\n","\n","for image, label in zip(ex_images, ex_labels):\n","    plot_image(image, label)\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"dp2zwEUHIzto"},"source":["## Defining the Dataset class\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UcVK-K5ru_8D"},"outputs":[],"source":["grayscale_to_rgb = lambda x: x.repeat(3, 1, 1)\n","\n","NORM_MEAN = (0.485, 0.456, 0.406)\n","NORM_STD = (0.229, 0.224, 0.225)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3NGI1b8rA0yM"},"outputs":[],"source":["class FER_Dataset_KFold(Dataset):\n","    def __init__(self, mode, indices=None, transform=None):\n","        # Train\n","        if mode == \"train\":\n","            if indices is None:\n","                self.dataset = train_images\n","                self.labels = train_labels\n","            else:\n","                self.dataset = train_images[indices]\n","                self.labels = train_labels[indices]\n","\n","        # Validation\n","        if mode == \"val\":\n","            if indices is None:\n","                self.dataset = val_images\n","                self.labels = val_labels\n","            else:\n","                self.dataset = train_images[indices]\n","                self.labels = train_labels[indices]\n","\n","        # Test\n","        if mode == \"test\":\n","            if indices is None:\n","                self.dataset = test_images\n","                self.labels = test_labels\n","            else:\n","                self.dataset = test_images[indices]\n","                self.labels = test_labels[indices]\n","\n","        # Transform\n","        if transform is not None:\n","            self.transform = transform\n","        else:\n","            self.transform = transforms.Compose(\n","                [\n","                    # Convert to RGB Tensor\n","                    transforms.ToTensor(),\n","                    transforms.Lambda(grayscale_to_rgb),\n","                    # Normalization\n","                    transforms.Normalize(mean=NORM_MEAN, std=NORM_STD),\n","                ]\n","            )\n","\n","    def __getitem__(self, idx):\n","        image = self.transform(self.dataset[idx])\n","        label = self.labels[idx]\n","\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def weights(self):\n","        dist = dataset_distribution(self.labels, verbose=False)\n","        label_weights = 1 / np.array(dist)\n","        samples_weights = label_weights[self.labels]\n","\n","        return samples_weights"]},{"cell_type":"markdown","metadata":{"id":"es5TXvHC_02X"},"source":["# Models\n"]},{"cell_type":"markdown","metadata":{"id":"N3UK4N6ar264"},"source":["## Defining the Lightning module\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GjvIeYhfScse"},"outputs":[],"source":["NUM_WORKERS = 2  # For dataloaders\n","\n","_SEP_LEN = 80  # For printing results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ox9N5DJ8TscK"},"outputs":[],"source":["class CNN_Classifier_KFold(pl.LightningModule):\n","    def __init__(\n","        self,\n","        model,\n","        train_indices=None,\n","        val_indices=None,\n","        lr=1e-4,\n","        batch_size=128,\n","        num_workers=NUM_WORKERS,\n","    ):\n","        super().__init__()\n","        self.model = model\n","        self.lr = lr\n","        self.batch_size = batch_size\n","        self.num_workers = num_workers\n","\n","        # K-fold cross-validation split\n","        self.train_indices = train_indices\n","        self.val_indices = val_indices\n","\n","        # Loss (weighted Cross-Entropy)\n","        weights = 1 / torch.FloatTensor(\n","            dataset_distribution(train_labels[train_indices], verbose=False)\n","        )\n","        self.loss = nn.CrossEntropyLoss(weights)\n","\n","        # Accuracy\n","        self.accuracy = torchmetrics.Accuracy(\"multiclass\", num_classes=NUM_LABELS)\n","\n","        # Save hyper-parameters\n","        self.save_hyperparameters(ignore=[\"model\"])\n","\n","        # Test step labels and predictions\n","        self.test_step_labels = []\n","        self.test_step_preds = []\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def _get_preds_loss_acc(self, images, labels):\n","        # Forward pass\n","        logits = self(images)\n","\n","        # Output probabilities\n","        probs = F.softmax(logits, dim=0)\n","\n","        # Predictions\n","        preds = torch.argmax(probs, dim=1)\n","\n","        # Loss\n","        loss = self.loss(logits, labels)\n","\n","        # Accuracy\n","        acc = self.accuracy(preds, labels)\n","\n","        return preds, loss, acc\n","\n","    def configure_optimizers(self):\n","        # Optimizer\n","        optimizer = optim.AdamW(self.parameters(), lr=self.lr, weight_decay=1e-3)\n","\n","        # Scheduler\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","            optimizer, mode=\"min\", factor=0.1, patience=10, min_lr=1e-7, verbose=True\n","        )\n","\n","        return {\n","            \"optimizer\": optimizer,\n","            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"},\n","        }\n","\n","    # Training\n","\n","    def train_dataloader(self):\n","        # Transforms\n","        train_transform = transforms.Compose(\n","            [\n","                # Convert to RGB Tensor\n","                transforms.ToTensor(),\n","                transforms.Lambda(grayscale_to_rgb),\n","                # Data augmentation\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ColorJitter(brightness=1, contrast=1, saturation=1),\n","                transforms.RandomAdjustSharpness(np.random.uniform(1, 6)),\n","                # Normalization\n","                transforms.Normalize(mean=NORM_MEAN, std=NORM_STD),\n","            ]\n","        )\n","\n","        # Dataset\n","        train_dataset = FER_Dataset_KFold(\"train\", self.train_indices, train_transform)\n","\n","        # Weighted sampler\n","        # weights = torch.FloatTensor(train_dataset.weights())\n","        # sampler = WeightedRandomSampler(weights, len(train_dataset))\n","\n","        # Dataloader\n","        train_dataloader = DataLoader(\n","            train_dataset,\n","            batch_size=self.batch_size,\n","            # sampler=sampler,\n","            shuffle=True,\n","            num_workers=self.num_workers,\n","            pin_memory=True,\n","        )\n","\n","        return train_dataloader\n","\n","    def training_step(self, batch, _):\n","        _, loss, acc = self._get_preds_loss_acc(*batch)\n","\n","        # Logging\n","        train_metrics = {\"train_loss\": loss, \"train_acc\": acc}\n","        self.log_dict(\n","            train_metrics,\n","            on_step=False,\n","            on_epoch=True,\n","            batch_size=self.batch_size,\n","            prog_bar=True,\n","            logger=True,\n","        )\n","\n","        return loss\n","\n","    # Validation\n","\n","    def val_dataloader(self):\n","        # Dataset\n","        val_dataset = FER_Dataset_KFold(\"val\", self.val_indices)\n","\n","        # Dataloader\n","        val_dataloader = DataLoader(\n","            val_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=False,\n","            num_workers=self.num_workers,\n","            pin_memory=True,\n","        )\n","\n","        return val_dataloader\n","\n","    def validation_step(self, batch, _):\n","        _, loss, acc = self._get_preds_loss_acc(*batch)\n","\n","        # Logging\n","        val_metrics = {\"val_loss\": loss, \"val_acc\": acc}\n","        self.log_dict(\n","            val_metrics,\n","            on_step=False,\n","            on_epoch=True,\n","            batch_size=self.batch_size,\n","            prog_bar=True,\n","            logger=True,\n","        )\n","\n","    # Testing\n","\n","    def test_dataloader(self):\n","        # Dataset\n","        test_dataset = FER_Dataset_KFold(\"test\")\n","\n","        # Dataloader\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=False,\n","            num_workers=self.num_workers,\n","            pin_memory=True,\n","        )\n","\n","        return test_dataloader\n","\n","    def test_step(self, batch, _):\n","        images, labels = batch\n","        preds, loss, acc = self._get_preds_loss_acc(images, labels)\n","\n","        self.test_step_labels.append(labels)\n","        self.test_step_preds.append(preds)\n","\n","        # Logging\n","        test_metrics = {\"test_loss\": loss, \"test_acc\": acc}\n","        self.log_dict(\n","            test_metrics,\n","            on_step=False,\n","            on_epoch=True,\n","            batch_size=self.batch_size,\n","            prog_bar=True,\n","            logger=True,\n","        )\n","\n","    def on_test_epoch_end(self):\n","        labels = torch.hstack(self.test_step_labels).cpu()\n","        preds = torch.hstack(self.test_step_preds).cpu()\n","\n","        # Calculate and log metrics\n","\n","        def _wandb_log_bar_plot(metric, title):\n","            fig, ax = plt.subplots()\n","            x = np.arange(NUM_LABELS)\n","            ax.bar(x, metric)\n","            ax.set_xticks(x, LABELS)\n","            ax.set_title(title)\n","            fig.tight_layout()\n","            wandb.log({title.lower(): wandb.Image(fig)})\n","            plt.close()\n","\n","        # Precision per label\n","        precision = precision_score(labels, preds, average=None)\n","        _wandb_log_bar_plot(precision, \"Precision\")\n","\n","        # Recall per label\n","        recall = recall_score(labels, preds, average=None)\n","        _wandb_log_bar_plot(recall, \"Recall\")\n","\n","        # F1 score per label\n","        f1 = f1_score(labels, preds, average=None)\n","        _wandb_log_bar_plot(f1, \"F1\")\n","\n","        # Confusion matrix\n","        cm = confusion_matrix(labels, preds, normalize=\"true\")\n","        df_cm = pd.DataFrame(cm, LABELS, LABELS)\n","        fig, ax = plt.subplots()\n","        sns.heatmap(df_cm, annot=True)\n","        ax.set_xlabel(\"Predictions\")\n","        ax.set_ylabel(\"Labels\")\n","        fig.tight_layout()\n","        wandb.log({\"confusion_matrix\": wandb.Image(fig)})\n","        plt.close()\n","\n","        # Generate and print test report\n","        report = classification_report(labels, preds)\n","        print()\n","        print(\"-\" * _SEP_LEN)\n","        print(\"Test report\")\n","        print(\"-\" * _SEP_LEN)\n","        print()\n","        print(report)\n","        print()\n","        print(\"-\" * _SEP_LEN)\n","        print()\n","\n","        # Clear lists\n","        self.test_step_labels.clear()\n","        self.test_step_preds.clear()"]},{"cell_type":"markdown","metadata":{"id":"z4xYUjULsDTl"},"source":["## Creating the models\n"]},{"cell_type":"markdown","metadata":{"id":"KdhNde4mrsl0"},"source":["Device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qS0uIr0UTFQR"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"2p_hgg2vDvr9"},"source":["Model architecture summary\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JCZsU4MsC38K"},"outputs":[],"source":["def model_summary(make_model):\n","    model = make_model()\n","    model.to(device)\n","    summary(model, input_size=(3, IM_H, IM_W))"]},{"cell_type":"markdown","metadata":{"id":"SGW64rdUCcPf"},"source":["Verifying that the model works\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kuzo4F3Y9SuU"},"outputs":[],"source":["def verify_model(make_model, batch_size=1):\n","    # Input data\n","    dataset = FER_Dataset_KFold(\"test\")\n","    data_loader = DataLoader(dataset, batch_size=batch_size)\n","    images, labels = next(iter(data_loader))\n","\n","    # Model\n","    model = make_model()\n","    model.to(device)\n","\n","    # Forward pass\n","    model.eval()\n","    logits = model(images.to(device))\n","    probs = F.softmax(logits, dim=0)\n","    preds = torch.argmax(probs, dim=1)\n","\n","    return preds, labels"]},{"cell_type":"markdown","metadata":{"id":"fCtmQIbFekSN"},"source":["### Model 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1u4qO1FF1UQ"},"outputs":[],"source":["def make_model_1():\n","    return nn.Sequential(\n","        # Features\n","        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5, stride=1, padding=1),\n","        # nn.BatchNorm2d(num_features=64),\n","        nn.MaxPool2d(kernel_size=2),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=1),\n","        # nn.BatchNorm2d(num_features=128),\n","        nn.MaxPool2d(kernel_size=2),\n","        nn.ReLU(),\n","        # Classifier\n","        nn.Flatten(),\n","        nn.Linear(in_features=128 * 10 * 10, out_features=128),\n","        nn.ReLU(),\n","        nn.Linear(in_features=128, out_features=NUM_LABELS),\n","    )\n","\n","\n","model_summary(make_model_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zr4gIN0WC0cd"},"outputs":[],"source":["verify_model(make_model_1)"]},{"cell_type":"markdown","metadata":{"id":"Waav9a1-Qbgw"},"source":["### Model 2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGgibHZHQehC"},"outputs":[],"source":["def make_model_2():\n","    return nn.Sequential(\n","        # Features\n","        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n","        # nn.BatchNorm2d(num_features=64),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2),\n","        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n","        # nn.BatchNorm2d(num_features=128),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2),\n","        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n","        # nn.BatchNorm2d(num_features=256),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2),\n","        # Classifier\n","        nn.Flatten(),\n","        nn.Linear(in_features=256 * 6 * 6, out_features=512),\n","        nn.ReLU(),\n","        nn.Dropout(p=0.5),\n","        nn.Linear(in_features=512, out_features=256),\n","        nn.ReLU(),\n","        nn.Dropout(p=0.5),\n","        nn.Linear(in_features=256, out_features=NUM_LABELS),\n","    )\n","\n","\n","model_summary(make_model_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HoyeodLulBUn"},"outputs":[],"source":["verify_model(make_model_2)"]},{"cell_type":"markdown","metadata":{"id":"C8y8a1COmFxh"},"source":["### Model 3\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8AcoxmFSMq7"},"outputs":[],"source":["def make_model_3():\n","    return nn.Sequential(\n","        # Features\n","        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, bias=False),\n","        nn.BatchNorm2d(num_features=64),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2),\n","        nn.Conv2d(\n","            in_channels=64, out_channels=128, kernel_size=5, padding=3, bias=False\n","        ),\n","        nn.BatchNorm2d(num_features=128),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2),\n","        nn.Conv2d(\n","            in_channels=128, out_channels=256, kernel_size=7, padding=5, bias=False\n","        ),\n","        nn.BatchNorm2d(num_features=256),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2),\n","        nn.Conv2d(\n","            in_channels=256, out_channels=512, kernel_size=5, padding=3, bias=False\n","        ),\n","        nn.BatchNorm2d(num_features=512),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2),\n","        # Classifier\n","        nn.Flatten(),\n","        nn.Linear(in_features=512 * 5 * 5, out_features=256),\n","        nn.ReLU(),\n","        nn.Dropout(p=0.5),\n","        nn.Linear(in_features=256, out_features=128),\n","        nn.ReLU(),\n","        nn.Dropout(p=0.5),\n","        nn.Linear(in_features=128, out_features=64),\n","        nn.ReLU(),\n","        nn.Dropout(p=0.5),\n","        nn.Linear(in_features=64, out_features=NUM_LABELS),\n","    )\n","\n","\n","model_summary(make_model_3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k6VWchuJlQpo"},"outputs":[],"source":["verify_model(make_model_3)"]},{"cell_type":"markdown","metadata":{"id":"P8nlUHLBsI5K"},"source":["### ResNet 50\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_7AO1QVjsPac"},"outputs":[],"source":["def make_resnet50():\n","    return nn.Sequential(\n","        models.resnet50(weights=\"DEFAULT\"), nn.Linear(1000, NUM_LABELS)\n","    )\n","\n","\n","model_summary(make_resnet50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XLLp6rb3la5X"},"outputs":[],"source":["verify_model(make_resnet50)"]},{"cell_type":"markdown","metadata":{"id":"pFpNW4kaebSn"},"source":["# Training\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N3uPu-gqFkWS"},"outputs":[],"source":["def train_model(\n","    make_base_model,\n","    project,\n","    run,\n","    train_indices=None,\n","    val_indices=None,\n","    lr=1e-4,\n","    max_epochs=100,\n","    min_epochs=20,\n","    save_on_drive=False,\n","):\n","    # Create an untrained version of the base model\n","    base_model = make_base_model()\n","\n","    # Create a new model to train on each split\n","    model = CNN_Classifier_KFold(base_model, train_indices, val_indices, lr=lr)\n","\n","    # Create a new WandB logger\n","    wandb_logger = WandbLogger(project=project, name=run)\n","\n","    # Save model with lowest val_loss\n","    checkpoint_callback = ModelCheckpoint(\n","        save_top_k=1,\n","        monitor=\"val_loss\",\n","        mode=\"min\",\n","        dirpath=f\"{project}/checkpoints/{run}/\",\n","        filename=project + \"_{epoch:02d}_{val_loss:0.3f}\",\n","    )\n","\n","    # Stop early if no improvement in val_loss\n","    early_stop_callback = EarlyStopping(\n","        monitor=\"val_loss\", mode=\"min\", min_delta=1e-6, patience=30\n","    )\n","\n","    # Create the trainer\n","    trainer = pl.Trainer(\n","        max_epochs=max_epochs,\n","        min_epochs=min_epochs,\n","        logger=wandb_logger,\n","        log_every_n_steps=1,\n","        accelerator=\"gpu\",\n","        devices=-1,\n","        callbacks=[checkpoint_callback, early_stop_callback],\n","        deterministic=True,\n","    )\n","\n","    # Train\n","    trainer.fit(model)\n","\n","    # Save checkpoints on WandB\n","    ckpt_dir = f\"{project}/checkpoints/{run}/\"\n","    wandb_ckpt_dir = os.path.join(wandb.run.dir, \"checkpoints\")\n","    os.mkdir(wandb_ckpt_dir)\n","    for checkpoint in os.listdir(ckpt_dir):\n","        shutil.copy(ckpt_dir + checkpoint, wandb_ckpt_dir)\n","\n","    # Save checkpoints on drive\n","    if save_on_drive:\n","        drive_save_path = DRIVE_DIR + f\"checkpoints/{project}/{run}/\"\n","\n","        # Create/clear directory\n","        if os.path.exists(drive_save_path):\n","            shutil.rmtree(drive_save_path)\n","        os.makedirs(drive_save_path)\n","\n","        # Save\n","        for checkpoint in os.listdir(ckpt_dir):\n","            shutil.copy(ckpt_dir + checkpoint, drive_save_path + checkpoint)\n","\n","    # Close logger\n","    wandb.finish()\n","\n","    return trainer\n","\n","\n","def train_kfold(make_base_model, k, project, lr=1e-4, max_epochs=100, min_epochs=20):\n","    # Get the splits\n","    splits = StratifiedKFold(n_splits=k).split(train_images, train_labels)\n","\n","    # Metrics\n","    avg_metrics = {\"train_loss\": 0, \"train_acc\": 0, \"val_loss\": 0, \"val_acc\": 0}\n","\n","    for i, (train_indices, val_indices) in enumerate(splits):\n","        # Print split distribution\n","        print(\"=\" * _SEP_LEN)\n","        print(f\"Split {i+1}/{k}\")\n","        print(\"=\" * _SEP_LEN)\n","        print()\n","        print(\"------ Train Dataset ------\")\n","        dataset_distribution(train_labels[train_indices])\n","        print()\n","        print(\"------ Validation Dataset ------\")\n","        dataset_distribution(train_labels[val_indices])\n","        print()\n","        print(\"-\" * _SEP_LEN)\n","        print()\n","\n","        # Train\n","        trainer = train_model(\n","            make_base_model,\n","            project=project,\n","            run=f\"split_{i+1}\",\n","            train_indices=train_indices,\n","            val_indices=val_indices,\n","            lr=lr,\n","            max_epochs=max_epochs,\n","            min_epochs=min_epochs,\n","        )\n","\n","        print()\n","\n","        # Update global metrics from callback\n","        print(\"-\" * _SEP_LEN)\n","        print(\"Callback metrics\")\n","        print(\"-\" * _SEP_LEN)\n","        print()\n","        callback_metrics = trainer.callback_metrics\n","        for metric in avg_metrics:\n","            value = callback_metrics[metric].item()\n","            avg_metrics[metric] += value\n","            print(f\"{metric}: {value}\")\n","\n","        print()\n","        print()\n","\n","    # Take average of metrics\n","    for metric in avg_metrics:\n","        avg_metrics[metric] /= k\n","\n","    # Log average metrics\n","    print(\"=\" * _SEP_LEN)\n","    print(f\"Average metrics over {k} splits\")\n","    print(\"=\" * _SEP_LEN)\n","    print()\n","    wandb.init(project=project, name=\"average_metrics\", dir=f\"{project}/\")\n","    wandb.log(\n","        {\n","            \"avg_metrics\": wandb.Table(\n","                data=[list(avg_metrics.values())], columns=list(avg_metrics.keys())\n","            )\n","        }\n","    )\n","\n","    # Close logger\n","    wandb.finish()\n","\n","    print()\n","\n","    # Print average metrics\n","    for metric in avg_metrics:\n","        print(f\"{metric}: {avg_metrics[metric]}\")\n","\n","    return avg_metrics"]},{"cell_type":"markdown","metadata":{"id":"LdHWl_X_Vpuu"},"source":["## K-fold cross validation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJsm_QV4p688"},"outputs":[],"source":["K = 5\n","\n","LR = 1e-5\n","MAX_EPOCHS = 60\n","MIN_EPOCHS = 40"]},{"cell_type":"markdown","metadata":{"id":"M4BWy8F_klfR"},"source":["Model 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1MgHXGbAQ4Iz"},"outputs":[],"source":["avg_metrics_1 = train_kfold(\n","    make_model_1,\n","    k=K,\n","    project=f\"model_1_k={K}\",\n","    lr=LR,\n","    max_epochs=MAX_EPOCHS,\n","    min_epochs=MIN_EPOCHS,\n",")"]},{"cell_type":"markdown","metadata":{"id":"Erv_z6sQkm2R"},"source":["Model 2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOQgyhrVUzD-"},"outputs":[],"source":["avg_metrics_2 = train_kfold(\n","    make_model_2,\n","    k=K,\n","    project=f\"model_2_k={K}\",\n","    lr=LR,\n","    max_epochs=MAX_EPOCHS,\n","    min_epochs=MIN_EPOCHS,\n",")"]},{"cell_type":"markdown","metadata":{"id":"PEP6fbiynqoW"},"source":["Model 3\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKpwGV9UnqN3"},"outputs":[],"source":["avg_metrics_3 = train_kfold(\n","    make_model_3,\n","    k=K,\n","    project=f\"model_3_k={K}\",\n","    lr=LR,\n","    max_epochs=MAX_EPOCHS,\n","    min_epochs=MIN_EPOCHS,\n",")"]},{"cell_type":"markdown","metadata":{"id":"UDHpZj8Zn0Qk"},"source":["### Comparison of average metrics from checkpoints\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Gyf6jBenz2q"},"outputs":[],"source":["all_metrics = [avg_metrics_1, avg_metrics_2, avg_metrics_3]\n","all_models = [\"model_1\", \"model_2\", \"model_3\"]\n","\n","all_metrics_df = pd.DataFrame.from_records(all_metrics, index=all_models)\n","\n","print(f\"Average metrics for each model over {K} splits\")\n","print()\n","print(all_metrics_df)"]},{"cell_type":"markdown","metadata":{"id":"TvYtRoDlVkSs"},"source":["## Training the best model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b-kTE0EUK0lr"},"outputs":[],"source":["make_best_model = make_model_2\n","PROJECT_BEST = \"best_model_2\"\n","RUN_BEST = \"train\"\n","\n","LR_BEST = 1e-5\n","MAX_EPOCHS_BEST = 400\n","MIN_EPOCHS_BEST = 0\n","\n","\n","_ = train_model(\n","    make_best_model,\n","    project=PROJECT_BEST,\n","    run=RUN_BEST,\n","    lr=LR_BEST,\n","    max_epochs=MAX_EPOCHS_BEST,\n","    min_epochs=MIN_EPOCHS_BEST,\n","    save_on_drive=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"-WcnOjBXVqNu"},"source":["# Testing\n"]},{"cell_type":"markdown","metadata":{"id":"dK6ZWWkycV4o"},"source":["## Testing best model from checkpoint\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpSe7GekcVJD"},"outputs":[],"source":["def load_all_checkpoints(make_base_model, project, run):\n","    checkpoint_dir = DRIVE_DIR + f\"checkpoints/{project}/{run}/\"\n","    checkpoints = {}\n","    for checkpoint in os.listdir(checkpoint_dir):\n","        checkpoint_path = checkpoint_dir + checkpoint\n","\n","        # Create an untrained version of the base model\n","        base_model = make_base_model()\n","\n","        # Load model parameters from checkpoint\n","        model = CNN_Classifier_KFold.load_from_checkpoint(\n","            checkpoint_path, model=base_model\n","        )\n","\n","        checkpoints[checkpoint] = model\n","\n","    return checkpoints\n","\n","\n","def test_checkpoints(make_base_model, project, run):\n","    # Load all models from checkpoints\n","    checkpoints = load_all_checkpoints(make_base_model, project, run)\n","\n","    for checkpoint in checkpoints:\n","        print(\"=\" * _SEP_LEN)\n","        print(f\"Testing {checkpoint}\")\n","        print(\"=\" * _SEP_LEN)\n","        print()\n","        print(\"------ Test Dataset ------\")\n","        dataset_distribution(test_labels)\n","        print()\n","        print(\"-\" * _SEP_LEN)\n","        print()\n","\n","        # Get model\n","        model = checkpoints[checkpoint]\n","\n","        # Create a new WandB logger\n","        wandb_logger = WandbLogger(project=project, name=f\"test_{checkpoint}\")\n","\n","        # Create trainer\n","        trainer = pl.Trainer(logger=wandb_logger, accelerator=\"gpu\", devices=-1)\n","\n","        # Test\n","        trainer.test(model)\n","\n","        # Close logger\n","        wandb.finish()\n","\n","        print()\n","        print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w8wIX60sfwke"},"outputs":[],"source":["test_checkpoints(make_best_model, PROJECT_BEST, RUN_BEST)"]},{"cell_type":"markdown","metadata":{"id":"m3M8R6dHRVHJ"},"source":["## Testing on real-life videos\n"]},{"cell_type":"markdown","metadata":{"id":"cmxSa_7BRwzN"},"source":["Load the videos\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8akmjcMqRvrE"},"outputs":[],"source":["videos_dir = DRIVE_DIR + \"videos/\"\n","\n","videos = {}\n","for video in os.listdir(videos_dir):\n","    if video.endswith(\".npy\"):\n","        label = video[:-4]\n","        video_array = np.load(videos_dir + video).astype(np.uint8)\n","        videos[label] = video_array\n","        print(f\"{label} --- {video_array.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"xrv_2heSqtd8"},"source":["Test\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"To0A9NPcRYz8"},"outputs":[],"source":["def test_on_videos(make_base_model, project, run, save_on_drive=False):\n","    # Load the pre-trained model\n","    checkpoints = load_all_checkpoints(make_base_model, project, run)\n","    model_name, model = list(checkpoints.items())[0]\n","    model = model.model.to(device)\n","\n","    frame_trans = transforms.Compose(\n","        [\n","            # Convert to Tensor\n","            transforms.ToTensor(),\n","            # Normalization\n","            transforms.Normalize(mean=NORM_MEAN, std=NORM_STD),\n","        ]\n","    )\n","\n","    for label, video_array in videos.items():\n","        frames = torch.stack([frame_trans(frame) for frame in video_array]).to(device)\n","\n","        model.eval()\n","\n","        # Forward pass\n","        logits = model(frames)\n","\n","        # Output probabilities\n","        probs = F.softmax(logits, dim=0)\n","\n","        # Predictions\n","        preds = torch.argmax(probs, dim=1)\n","\n","        # Plot predictions distribution\n","        preds_array = preds.cpu().numpy()\n","\n","        preds_dist = np.empty((NUM_LABELS,))\n","        for i in range(NUM_LABELS):\n","            preds_dist[i] = sum(preds_array == i) / len(preds_array)\n","\n","        fig, ax = plt.subplots()\n","        ax.bar(np.arange(NUM_LABELS), preds_dist)\n","        ax.set_xticks(np.arange(NUM_LABELS), LABELS)\n","        ax.set_title(label.capitalize())\n","        plt.show()\n","\n","        # Save on drive\n","        if save_on_drive:\n","            drive_save_path = videos_dir + \"preds/\" + f\"{model_name}_preds_{label}.jpg\"\n","            fig.savefig(drive_save_path, bbox_inches=\"tight\")\n","\n","        print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2IkFlkRIccQN"},"outputs":[],"source":["test_on_videos(make_best_model, PROJECT_BEST, RUN_BEST, save_on_drive=True)"]},{"cell_type":"markdown","metadata":{"id":"q6OWXcLC2EUL"},"source":["## Comparison with ResNet50\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x6Fi72bf2KU6"},"outputs":[],"source":["PROJECT_RN = \"resnet50\"\n","RUN_RN = \"train\"\n","\n","LR_RN = 1e-5\n","MAX_EPOCHS_RN = 400\n","MIN_EPOCHS_RN = 0\n","\n","\n","_ = train_model(\n","    make_resnet50,\n","    project=PROJECT_RN,\n","    run=RUN_RN,\n","    lr=LR_RN,\n","    max_epochs=MAX_EPOCHS_RN,\n","    min_epochs=MIN_EPOCHS_RN,\n","    save_on_drive=True,\n",")\n","\n","test_checkpoints(make_resnet50, PROJECT_RN, RUN_RN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S-qzWTS-dznH"},"outputs":[],"source":["test_on_videos(make_resnet50, PROJECT_RN, RUN_RN, save_on_drive=True)"]},{"cell_type":"markdown","metadata":{"id":"tW8myqXo2p1M"},"source":["# Activations visualization\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I2pIxEptfFng"},"outputs":[],"source":["def visualize_activations(\n","    model, image, save_on_drive=False, save_dir=None, base_save_as=None\n","):\n","    # Get base model\n","    model = model.model\n","\n","    # Collect the activations\n","    activations = {}\n","\n","    def get_activations(i):\n","        def hook(module, input, output):\n","            activations[i] = output.detach().cpu()\n","\n","        return hook\n","\n","    # Register the hooks for convolutional layers\n","    hook_handles = []\n","    i = 0\n","    for module in model.modules():\n","        if isinstance(module, nn.Conv2d):\n","            hook_handle = module.register_forward_hook(get_activations(i))\n","            hook_handles.append(hook_handle)\n","            i += 1\n","\n","    # Save on drive\n","    if save_on_drive:\n","        drive_save_dir = DRIVE_DIR + \"visualizations/\" + save_dir\n","\n","        # Create/clear directory\n","        if os.path.exists(drive_save_dir):\n","            shutil.rmtree(drive_save_dir)\n","        os.makedirs(drive_save_dir)\n","\n","    # Forward pass\n","    model.eval()\n","    model(image.to(device))\n","\n","    # Visualize the activations\n","    for i, activation in activations.items():\n","        num_channels = activation.size(1)\n","        num_rows = (num_channels + 7) // 8\n","        num_cols = min(8, num_channels)\n","\n","        fig, axes = plt.subplots(\n","            num_rows, num_cols, figsize=(2 * num_cols, 2 * num_rows)\n","        )\n","\n","        for channel_idx, ax in enumerate(axes.flatten()):\n","            if channel_idx < num_channels:\n","                channel_activation = activation[0, channel_idx, :, :]\n","                ax.imshow(channel_activation, cmap=\"gray\")\n","                ax.axis(\"off\")\n","                ax.set_title(f\"Channel {channel_idx+1}\")\n","\n","        # Remove any unused subplots\n","        for unused_ax in axes.flatten()[num_channels:]:\n","            unused_ax.remove()\n","\n","        plt.suptitle(\n","            f\"Convolutional layer {i+1} ({num_channels} channels)\", fontsize=16\n","        )\n","        plt.tight_layout(rect=[0, 0, 1, 0.98])  # Move the suptitle above the subplots\n","        plt.show()\n","\n","        # Save on drive\n","        if save_on_drive:\n","            drive_save_path = drive_save_dir + f\"Conv_Layer_{i+1}.jpg\"\n","            fig.savefig(drive_save_path, bbox_inches=\"tight\")\n","\n","    # Remove the hook handles to release the memory\n","    for handle in hook_handles:\n","        handle.remove()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AImyFoRnoIoW"},"outputs":[],"source":["# Load the pre-trained model\n","checkpoints = load_all_checkpoints(make_best_model, PROJECT_BEST, RUN_BEST)\n","model_name, model = list(checkpoints.items())[0]\n","\n","vis_dataset = FER_Dataset_KFold(\"test\", ex_indices)\n","vis_dataloader = DataLoader(vis_dataset, batch_size=1, shuffle=False)\n","\n","# Visualize and save activations\n","for image, label in vis_dataloader:\n","    print(LABELS[label])\n","    visualize_activations(\n","        model,\n","        image,\n","        save_on_drive=True,\n","        save_dir=f\"{model_name}/{LABELS[label]}/\",\n","        base_save_as=model_name,\n","    )\n","    print()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
